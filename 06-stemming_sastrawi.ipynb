{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('clean_dataset.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>step01</th>\n",
       "      <th>tokens</th>\n",
       "      <th>final_tokens</th>\n",
       "      <th>step02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cegah mata rantai Covid-19,mari kita dirumah s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cegah mata rantai covid   mari kita dirumah sa...</td>\n",
       "      <td>['cegah', 'mata', 'rantai', 'covid', 'mari', '...</td>\n",
       "      <td>['cegah', 'mata', 'rantai', 'covid', 'mari', '...</td>\n",
       "      <td>cegah mata rantai covid mari kita dirumah saja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aku mohon yaAllah semoga wabah covid-19 menghi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aku mohon yaallah semoga wabah covid   menghil...</td>\n",
       "      <td>['aku', 'mohon', 'yaallah', 'semoga', 'wabah',...</td>\n",
       "      <td>['aku', 'mohon', 'yaallah', 'semoga', 'wabah',...</td>\n",
       "      <td>aku mohon yaallah semoga wabah covid menghilan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Pemprov Papua Naikkan Status Jadi Tanggap Daru...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pemprov papua naikkan status jadi tanggap daru...</td>\n",
       "      <td>['pemprov', 'papua', 'naikkan', 'status', 'jad...</td>\n",
       "      <td>['pemprov', 'papua', 'naikkan', 'status', 'jad...</td>\n",
       "      <td>pemprov papua naikkan status jadi tanggap daru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>['covid', 'belum', 'nyampe', 'prigen', 'mbak',...</td>\n",
       "      <td>['covid', 'belum', 'nyampe', 'prigen', 'mbak',...</td>\n",
       "      <td>covid belum nyampe prigen mbak hmm hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Nyuruh orang pintar, lu aja Togog. Itu kerumun...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>nyuruh orang pintar lu aja togog itu kerumunan...</td>\n",
       "      <td>['nyuruh', 'orang', 'pintar', 'lu', 'aja', 'to...</td>\n",
       "      <td>['nyuruh', 'orang', 'pintar', 'lu', 'aja', 'to...</td>\n",
       "      <td>nyuruh orang pintar lu aja togog itu kerumunan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Tweet  Sentimen  \\\n",
       "0           0  Cegah mata rantai Covid-19,mari kita dirumah s...       1.0   \n",
       "1           1  aku mohon yaAllah semoga wabah covid-19 menghi...       1.0   \n",
       "2           2  Pemprov Papua Naikkan Status Jadi Tanggap Daru...       1.0   \n",
       "3           3            Covid belum nyampe prigen mbak hmm hoax       0.0   \n",
       "4           4  Nyuruh orang pintar, lu aja Togog. Itu kerumun...      -1.0   \n",
       "\n",
       "                                              step01  \\\n",
       "0  cegah mata rantai covid   mari kita dirumah sa...   \n",
       "1  aku mohon yaallah semoga wabah covid   menghil...   \n",
       "2  pemprov papua naikkan status jadi tanggap daru...   \n",
       "3            covid belum nyampe prigen mbak hmm hoax   \n",
       "4  nyuruh orang pintar lu aja togog itu kerumunan...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['cegah', 'mata', 'rantai', 'covid', 'mari', '...   \n",
       "1  ['aku', 'mohon', 'yaallah', 'semoga', 'wabah',...   \n",
       "2  ['pemprov', 'papua', 'naikkan', 'status', 'jad...   \n",
       "3  ['covid', 'belum', 'nyampe', 'prigen', 'mbak',...   \n",
       "4  ['nyuruh', 'orang', 'pintar', 'lu', 'aja', 'to...   \n",
       "\n",
       "                                        final_tokens  \\\n",
       "0  ['cegah', 'mata', 'rantai', 'covid', 'mari', '...   \n",
       "1  ['aku', 'mohon', 'yaallah', 'semoga', 'wabah',...   \n",
       "2  ['pemprov', 'papua', 'naikkan', 'status', 'jad...   \n",
       "3  ['covid', 'belum', 'nyampe', 'prigen', 'mbak',...   \n",
       "4  ['nyuruh', 'orang', 'pintar', 'lu', 'aja', 'to...   \n",
       "\n",
       "                                              step02  \n",
       "0  cegah mata rantai covid mari kita dirumah saja...  \n",
       "1  aku mohon yaallah semoga wabah covid menghilan...  \n",
       "2  pemprov papua naikkan status jadi tanggap daru...  \n",
       "3            covid belum nyampe prigen mbak hmm hoax  \n",
       "4  nyuruh orang pintar lu aja togog itu kerumunan...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load sastrawi sebagai stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hapus stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n",
    " \n",
    "factory = StopWordRemoverFactory()\n",
    "\n",
    "more_stopword = ['sih', 'nya','rt','loh','lah', 'dd', 'mah', 'nye', 'eh', 'ehh', 'ah', 'yang','yg']\n",
    " \n",
    "# Tambahkan Stopword Baru\n",
    "data = factory.get_stop_words()+more_stopword\n",
    "\n",
    "stopwords_sastrawi = factory.create_stop_word_remover()\n",
    "\n",
    "dictionary = ArrayDictionary(data)\n",
    "str_stopwords = StopWordRemover(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['finalText_str'] = dataset['step02'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "final_string = []\n",
    "s = \"\"\n",
    "for sentence in dataset[\"finalText_str\"].values:\n",
    "    filteredSentence = []\n",
    "    EachReviewText = \"\"\n",
    "    st = str_stopwords.remove(sentence)\n",
    "    s = (stemmer.stem(st))\n",
    "    filteredSentence.append(s)\n",
    "    \n",
    "    EachReviewText = ' '.join(filteredSentence)\n",
    "    final_string.append(EachReviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[:, ('ProcessedText')] = final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('clean_dataset_stem.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
